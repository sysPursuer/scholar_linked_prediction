unsupervised
feature
selection
word
perspective
key
step
machine
learning
applications
categorization
clustering
text
data
original
matrix
sparse
performance
algorithms
labeling
training
instance
expensive
attracted
attention
paper
propose
algorithm
advantages
takes
input
dense
avoiding
sparseness
selects
basis
features
process
guaranteeing
space
adopts
random
projection
speed
extensive
experimental
proposed
approach
achieves
comparing
supervised
methods
classification
tasks
